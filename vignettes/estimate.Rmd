---
title: "More Details on the Estimation Procedure"
author: ""
date: ""
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{More Details on the Estimation Procedure}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
```{r, include=FALSE}
  library(ctsmTMB)
```

In this vignette we elaborate on the abilities and workings of the `estimate` method.

We consider the Ornstein-Uhlenbeck process, with a direct observation equation:
$$ 
\mathrm{d}x_{t} = \theta (\mu - x_{t}) \, \mathrm{d}t \, + \sigma_{x} \, \mathrm{d}b_{t} 
$$

$$
y_{t_{k}} = x_{t_{k}} + \varepsilon_{t_{k}} \qquad \varepsilon_{t_{k}} \sim N(0,\sigma_{y}^{2})
$$

```{r, include=FALSE}
# Simulate data using Euler Maruyama
set.seed(10)
theta=10; mu=1; sigma_x=1; sigma_y=1e-1
# 
dt.sim = 1e-3
t.sim = seq(0,1,by=dt.sim)
dw = rnorm(length(t.sim)-1,sd=sqrt(dt.sim))
x = 3
for(i in 1:(length(t.sim)-1)) {
  x[i+1] = x[i] + theta*(mu-x[i])*dt.sim + sigma_x*dw[i]
}

# Extract observations and add noise
dt.obs = 1e-2
t.obs = seq(0,1,by=dt.obs)
y = x[t.sim %in% t.obs] + sigma_y * rnorm(length(t.obs))

# Create data
.data = data.frame(
  t = t.obs,
  y = y
)
```

First we construct the `ctsmTMB` model object as per usual:

```{r}
# Create model object
model = ctsmTMB$new()

# Add system equations
model$addSystem(
  dx ~ theta * (mu-x) * dt + sigma_x*dw
)

# Add observation equations
model$addObs(
  y ~ x
)

# Set observation equation variances
model$setVariance(
  y ~ sigma_y^2
)

# Specify algebraic relations
model$setAlgebraics(
  theta ~ exp(logtheta),
  sigma_x ~ exp(logsigma_x),
  sigma_y ~ exp(logsigma_y)
)

# Specify parameter initial values and lower/upper bounds in estimation
model$setParameter(
  logtheta   = log(c(initial = 5,    lower = 0,    upper = 20)),
  mu         = c(    initial = 0,    lower = -10,  upper = 10),
  logsigma_x = log(c(initial = 1e-1, lower = 1e-5, upper = 5)),
  logsigma_y = log(c(initial = 1e-1, lower = 1e-5, upper = 5))
)

# Set initial state mean and covariance
model$setInitialState(list(x[1], 1e-1*diag(1)))
```

```{r, include=FALSE, eval=FALSE}
temporary_directory <- normalizePath(file.path(tempdir(),"ctsmTMB_cppfiles"))
model$setCppfilesDirectory(temporary_directory)
```


# Estimation

---

We are now ready to estimate the (fixed effects) parameters and states of the model by calling
```{r, eval=FALSE}
model$estimate(.data)
```

The arguments and their defaults when calling are:
```{r, eval=FALSE}
model$estimate(
  data,
  method = "ekf",
  ode.solver = "rk4",
  ode.timestep = diff(data$t),
  loss = "quadratic",
  loss_c = 3,
  unscented_hyperpars = list(alpha = 1, beta = 0, kappa = 3 - private$number.of.states),
  control = list(trace = 1, iter.max = 1e+05, eval.max = 1e+05),
  use.hessian = FALSE,
  laplace.residuals = FALSE,
  unconstrained.optim = FALSE,
  estimate.initial.state = FALSE,
  compile = FALSE,
  silent = FALSE
)
```

We now go through out of the arguments and explain in detail their workings

# Arguments:

## `method`

The `method` argument decides which estimation/filtering algorithm is used. Currently, the following arguments are accepted by `method`:

1. `method='lkf'`: The Linear "Exact" Kalman Filter (RTMB).

2. `method='ekf'`: The Extended Kalman Filter (RTMB).

3. `method='ukf_cpp'`: The Unscented Kalman Filter (TMB).

4. `method='ekf_cpp'`: The Extended Kalman Filter (TMB).

5. `method='laplace'`: The Laplace Approximation (RTMB).

### Filtering Technique

The package offers two filtering approaches. The first approach is that of **Kalman Filtering** (1-4) while the second approach is through the so-called **Laplace Approxmation** (5).

  1. The **Kalman Filtering** method is a recursive algorithm where the state is continuously being predicted forwards in time where until a measurement is available, and then updated using (information from) that measurement. Importantly, this recursiveness produces so-called prior and posterior state estimates, estimates which are conditional on observations up to the past and present respectively.

<!-- The filtering algorithm is optimal when the state space model is linear (i.e. linear drift and constant diffusion) and observation noise is Gaussian. -->

  2. The **Laplace Approximation** method is non-recursive in contrast to the Kalman filtering, and the produced state estimates, referred to as smoothed estimates, are therefore conditional on all observation in the data.
  


### TMB vs RTMB

The second difference to emphasize is the final parenthesis for each method, highlighting whether TMB or RTMB is used to construct the likelihood function. The former requires writing and compiling a C++ function, while the latter does not. 

The primary difference in these methods should be made between methods 1-4 which are Kalman filtering methods, and 5 which is an altogether different approach to state and likelihood estimation.

The former two are quite similar in that they are based on the Kalman Filter theory. The assumptions of normality in the state transition and observation equation are fundamental, although the implemented filters are standard non-linear filters, in the sense that they try to overcome these assumptions for small non-linearities. The Unscented Kalman Filter is generally considered to perform better in these cases.

<!-- The Extended Kalman Filter linearizes (to first order in the drift, and zeroth order in the diffusion) around the expectation of the state value to obtain prior and posterior state estimates as a way to handle non-linearities in system and observation equations.  -->

The latter `laplace` method employs the Laplace Approximation method of \code{link{TMB}} to integration out random effects. In this formulation we consider the states as random effects, and parameters as fixed. The underlying assumption is one of normality, but its implementation allows for the flexibility of choosing arbitrary distributions (not yet implemented.)

Both of these methods can be used to estimate parameter and states. In the case of `laplace` the states will be smoothed (conditioned on both past and future observations).

## **Note on C++ model changes**

---

This note is only relevant if you are using the `method="ekf_cpp"`. If you make changes to the model equations but retain the model name, then the underlying C++ function must be recompiled. You do this by specifying
```{r, eval=FALSE}
model$estimate(data, compile=TRUE)
```
If you receive error messages when calling `estimate` regarding variables that are not in your specified model, it is likely because you forgot to recompile.

# Argument: `ode.solver`

---

This argument is only used by the Kalman Filter methods i.e. `ekf` and `ukf`. The argument determines the algorithm used to integrate forward the moment (mean and variance) differential equations. The current implementation supports

1. `ode.solver='euler'`: The forward Euler scheme
2. `ode.solver='rk4'`: The 4th order Runge-Kutta scheme

# Argument: `ode.timestep`

---

This argument determines the time-step used in the ODE solvers


# Argument: `loss` and `loss_c`

---


# Argument: `use_hessian`

---

# Argument: `compile`

---

# Argument: `control`

---

```{r clean up, include=FALSE, eval=FALSE}
unlink(temporary_directory, recursive=TRUE)
```
